{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:10:21.173930Z",
     "start_time": "2025-06-17T14:10:21.170087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import Recommendation_models as rm\n",
    "import Filtering as fl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torchvision \n",
    "import torch.utils.data as data\n",
    "import torch.distributions as dist"
   ],
   "id": "ac511b53e335e38c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DATA PREPARATION",
   "id": "b787acfa33dac356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Spatial_F_AE(nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(Spatial_F_AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(k,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,k),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        final = self.decoder(z)\n",
    "        return final"
   ],
   "id": "faf7d54786d33eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Spatial_F_AE2(nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(Spatial_F_AE2, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(k,750),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(750,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,75),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(75,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,75),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(75,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,750),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(750,k),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        final = self.decoder(z)\n",
    "        return final"
   ],
   "id": "f1afdce21d4048f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, dataloader, criterion, optimizer, num_epochs, scheduler=None, best_loss=float('inf')):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            inputs = batch[0]\n",
    "            inputs = inputs.to(device)\n",
    "            recon = model(inputs)\n",
    "            loss = criterion(recon, inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(loss.item())\n",
    "            running_loss += loss.item()\n",
    "        losses.append(running_loss / (i + 1))\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Epoch {epoch+1}: Loss = {running_loss / (i + 1):.10f}\")\n",
    "    return losses"
   ],
   "id": "2ac61e510b417607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_books = pd.read_csv('books_autorec.csv')\n",
    "df_books.sort_values(by='ratings_count', ascending=False, inplace=True)\n",
    "#for aumenting books number change \n",
    "Books_number = 2000\n",
    "df_books = df_books.iloc[:Books_number]\n",
    "df_books.to_csv('Spatial_model_books.csv')\n",
    "df_books['goodreads_book_id'] = df_books['goodreads_book_id'].astype(int)\n",
    "book_ids = df_books['goodreads_book_id']\n"
   ],
   "id": "43c9b8cfe6714a6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_books = pd.read_csv('Spatial_model_books.csv')",
   "id": "fef55fbd411cf621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"books_autorec.csv\")\n",
    "df_ratings = pd.read_csv(\"ratings_autorec.csv\")\n",
    "\n",
    "df_ratings_with_clusters = df_ratings.merge(\n",
    "    df[['goodreads_book_id', 'cluster']], \n",
    "    left_on='book_id', \n",
    "    right_on='goodreads_book_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# create dictionary with user and ratings\n",
    "sparse_users = {}\n",
    "for user_id, group in df_ratings_with_clusters.groupby('user_id'):\n",
    "    books_ratings_clusters = group[['book_id', 'rating', 'cluster']].values.tolist()\n",
    "    sparse_users[user_id] = books_ratings_clusters\n",
    "\n",
    "cluster_sizes = df_books['cluster'].value_counts().sort_index().values\n",
    "\n",
    "filter_users = {\n",
    "    user: [triplet for triplet in triplets if triplet[0] in book_ids]\n",
    "    for user, triplets in sparse_users.items()\n",
    "}\n",
    "filter_users = {user: triplets for user, triplets in filter_users.items() if triplets}\n",
    "#user taken\n",
    "taken_users = 20000\n",
    "filter_users = sorted(filter_users.items(), key=lambda x: len(x[1]), reverse=True)[:taken_users]\n",
    "filter_users = dict(filter_users)\n"
   ],
   "id": "c96814253d3bbcef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(len(sparse_users))\n",
    "print(len(filter_users))"
   ],
   "id": "570751a1113b2716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mapping_pos_to_books = dict(zip(range(Books_number), book_ids))\n",
    "mapping_books_to_pos = dict(zip(book_ids,range(Books_number)))\n",
    "mapping_pos_to_users = dict(zip(range(taken_users), filter_users.keys()))\n",
    "mapping_users_to_pos = dict(zip(filter_users.keys(),range(taken_users)))\n",
    "print(len(mapping_pos_to_books))\n",
    "print(len(mapping_books_to_pos))\n",
    "print(len(mapping_pos_to_users))\n",
    "print(len(mapping_users_to_pos))"
   ],
   "id": "72f21a1caf8593ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_books = len(mapping_books_to_pos)\n",
    "user_vectors = []\n",
    "for user_id, triplets in filter_users.items():\n",
    "    vector = np.zeros(n_books)  # inizializza vettore di zeri\n",
    "\n",
    "    for book_id, rating, _ in triplets:\n",
    "        if book_id in mapping_books_to_pos:  # se il book_id Ã¨ tra quelli mappati\n",
    "            index = mapping_books_to_pos[book_id]\n",
    "            vector[index] = rating  # inserisci il rating nella posizione giusta\n",
    "\n",
    "    user_vectors.append(vector)\n",
    "print(len(user_vectors))\n",
    "print(len(user_vectors[0]))\n",
    "for i in range(len(user_vectors)):\n",
    "    user_vectors[i] = [0 if elem < 3 else 1 for elem in user_vectors[i]]\n",
    "print(user_vectors[0])\n",
    "df_input_data = pd.DataFrame(user_vectors)"
   ],
   "id": "6ad56bef5ae27e02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#df_input_data = pd.read_csv('Spatial_model_inputs.csv')\n",
    "tensor_data = torch.tensor(df_input_data.values, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(tensor_data)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "id": "ca50845294943919"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = rm.Spatial_F_AE(Books_number)\n",
    "criterion = nn.MSELoss()\n",
    "N_Epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=False)"
   ],
   "id": "351d95643e65b189"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "losses = train(model,dataloader,criterion, optimizer, N_Epochs, scheduler)",
   "id": "3ac94c4d91633bb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "rm.loss_graph(losses, N_Epochs)",
   "id": "e6884def138b4dac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model2 = Spatial_F_AE2(Books_number)\n",
    "criterion = nn.MSELoss()\n",
    "N_Epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=False)"
   ],
   "id": "80f398fa22e8d675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "losses = train(model,dataloader,criterion, optimizer, N_Epochs, scheduler)\n",
    "rm.loss_graph(losses, N_Epochs)"
   ],
   "id": "ec8a717e1e8cd07b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recomandations(user, model):\n",
    "    model.eval()\n",
    "    recon = model(user)\n",
    "    old_books= (user != 0).nonzero(as_tuple=True)[0].tolist()\n",
    "    _, new_books = torch.topk(recon, 25)\n",
    "    new_books = new_books.tolist()\n",
    "    old_books_map = [mapping_pos_to_books[pos] for pos in old_books]\n",
    "    new_books_map = [mapping_pos_to_books[pos] for pos in new_books]\n",
    "    old_titles = [df_books[df_books['goodreads_book_id'] == id].values.tolist()[0][5] for id in old_books_map]\n",
    "    new_titles = [df_books[df_books['goodreads_book_id'] == id].values.tolist()[0][5] for id in new_books_map]\n",
    "    diff = list(set(new_titles) - set(old_titles))\n",
    "    diff_id = list(set(new_books_map) - set(old_books_map))\n",
    "    return diff, diff_id, old_books_map"
   ],
   "id": "76946a746ce5ab1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
