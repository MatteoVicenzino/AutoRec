{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7133b4e8",
   "metadata": {},
   "source": [
    "# Autoencoder Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torchvision \n",
    "import torch.utils.data as data\n",
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f678c39",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d9330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('books_autorec.csv')\n",
    "df_books.sort_values(by='ratings_count', ascending=False, inplace=True)\n",
    "Books_number = 2000\n",
    "df_books = df_books.iloc[:Books_number]\n",
    "df_books.to_csv('Spatial_model_books.csv')\n",
    "df_books['goodreads_book_id'] = df_books['goodreads_book_id'].astype(int)\n",
    "book_ids = df_books['goodreads_book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e44f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv('Spatial_model_books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cad950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books_autorec.csv\")\n",
    "df_ratings = pd.read_csv(\"ratings_autorec.csv\")\n",
    "\n",
    "df_ratings_with_clusters = df_ratings.merge(\n",
    "    df[['goodreads_book_id', 'cluster']], \n",
    "    left_on='book_id', \n",
    "    right_on='goodreads_book_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# create dictionary with user and ratings\n",
    "sparse_users = {}\n",
    "for user_id, group in df_ratings_with_clusters.groupby('user_id'):\n",
    "    books_ratings_clusters = group[['book_id', 'rating', 'cluster']].values.tolist()\n",
    "    sparse_users[user_id] = books_ratings_clusters\n",
    "\n",
    "cluster_sizes = df_books['cluster'].value_counts().sort_index().values\n",
    "\n",
    "filter_users = {\n",
    "    user: [triplet for triplet in triplets if triplet[0] in book_ids]\n",
    "    for user, triplets in sparse_users.items()\n",
    "}\n",
    "filter_users = {user: triplets for user, triplets in filter_users.items() if triplets}\n",
    "#user taken\n",
    "taken_users = 50000\n",
    "filter_users = sorted(filter_users.items(), key=lambda x: len(x[1]), reverse=True)[:taken_users]\n",
    "filter_users = dict(filter_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ac99d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53424\n",
      "48939\n"
     ]
    }
   ],
   "source": [
    "print(len(sparse_users))\n",
    "print(len(filter_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33aeea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n",
      "48939\n",
      "48939\n"
     ]
    }
   ],
   "source": [
    "mapping_pos_to_books = dict(zip(range(Books_number), book_ids))\n",
    "mapping_books_to_pos = dict(zip(book_ids,range(Books_number)))\n",
    "mapping_pos_to_users = dict(zip(range(taken_users), filter_users.keys()))\n",
    "mapping_users_to_pos = dict(zip(filter_users.keys(),range(taken_users)))\n",
    "print(len(mapping_pos_to_books))\n",
    "print(len(mapping_books_to_pos))\n",
    "print(len(mapping_pos_to_users))\n",
    "print(len(mapping_users_to_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750eb98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48939\n",
      "2000\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "n_books = len(mapping_books_to_pos)\n",
    "user_vectors = []\n",
    "for user_id, triplets in filter_users.items():\n",
    "    vector = np.zeros(n_books)  # initialize vector with zeros\n",
    "\n",
    "    for book_id, rating, _ in triplets:\n",
    "        if book_id in mapping_books_to_pos:  # if book_id is in the mapping\n",
    "            index = mapping_books_to_pos[book_id]\n",
    "            vector[index] = rating  # insert rating in the correct position\n",
    "\n",
    "    user_vectors.append(vector)\n",
    "print(len(user_vectors))\n",
    "print(len(user_vectors[0]))\n",
    "for i in range(len(user_vectors)):\n",
    "    user_vectors[i] = [0 if elem < 3 else 1 for elem in user_vectors[i]]\n",
    "print(user_vectors[0])\n",
    "df_input_data = pd.DataFrame(user_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4873d3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0e4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spatial_F_AE(nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(Spatial_F_AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(k,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,125),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(125,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,k),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        final = self.decoder(z)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85667552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, num_epochs, scheduler=None, best_loss=float('inf')):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            inputs = batch[0]\n",
    "            inputs = inputs.to(device)\n",
    "            recon = model(inputs)\n",
    "            loss = criterion(recon, inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(loss.item())\n",
    "            running_loss += loss.item()\n",
    "        losses.append(running_loss / (i + 1))\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Epoch {epoch+1}: Loss = {running_loss / (i + 1):.10f}\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc5c327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_graph(tr_loss,n_epochs):\n",
    "    plt.plot(range(n_epochs),tr_loss,label='tr_loss', c='black')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c295695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data = torch.tensor(df_input_data.values, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(tensor_data)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d543211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteovicenzino/Documents/UNI/3_anno_24_25/ML/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model = Spatial_F_AE(Books_number)\n",
    "criterion = nn.MSELoss()\n",
    "N_Epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=False)\n",
    "\n",
    "losses = train(model,dataloader,criterion, optimizer, N_Epochs, scheduler)\n",
    "loss_graph(losses, N_Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbb325",
   "metadata": {},
   "source": [
    "## Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(user, model):\n",
    "    model.eval()\n",
    "    recon = model(user)\n",
    "    old_books= (user != 0).nonzero(as_tuple=True)[0].tolist()\n",
    "    _, new_books = torch.topk(recon, 100) # top 100 recommendations\n",
    "    new_books = new_books.tolist()\n",
    "    old_books_map = [mapping_pos_to_books[pos] for pos in old_books]\n",
    "    new_books_map = [mapping_pos_to_books[pos] for pos in new_books]\n",
    "    old_titles = [df_books[df_books['goodreads_book_id'] == id].values.tolist()[0][5] for id in old_books_map]\n",
    "    new_titles = [df_books[df_books['goodreads_book_id'] == id].values.tolist()[0][5] for id in new_books_map]\n",
    "    diff = list(set(new_titles) - set(old_titles))\n",
    "    diff_id = list(set(new_books_map) - set(old_books_map))\n",
    "    return diff, diff_id, old_books_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b87b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendations for user 678: \n",
      "['A Tale of Two Cities', 'Memoirs of a Geisha', 'Angels & Demons ', ' The Fellowship of the Ring', 'Un di Velt Hot Geshvign', 'Pippi Långstrump', 'The Da Vinci Code', 'The Curious Incident of the Dog in the Night-Time', 'Modern Romance', 'Of Mice and Men ', 'High Five', 'Freakonomics: A Rogue Economist Explores the Hidden Side of Everything', 'A Confederacy of Dunces', 'Ὀδύσσεια', 'O Alquimista', 'The Tragicall Historie of Hamlet, Prince of Denmark', 'The Boston Girl', 'Beautiful Creatures']\n",
      "[960, 1953, 930, 34, 865, 1381, 19302, 968, 22450859, 1420, 6304335, 1617, 1202, 1618, 310612, 6423, 23453112, 890]\n"
     ]
    }
   ],
   "source": [
    "rec, rec_id, old_id = recommendations(dataloader.dataset[678][0], model)\n",
    "print(\"Recommendations for user 678: \")\n",
    "print(rec)\n",
    "print(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53567212",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9180f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0babcdb3",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd31f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_refinding(model,user):\n",
    "    rating_pos = user[user == 1.0]\n",
    "    removed_pos = rating_pos[:int(len(rating_pos)/5)+1]\n",
    "    removed_books = [mapping_pos_to_books[elem] for elem in removed_pos.tolist()]\n",
    "    _, diff_id, _ = recommendations(user, model)\n",
    "    diff = list(set(removed_books) - set(diff_id))\n",
    "    return len(diff)/len(removed_books), len(removed_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd70ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(mapping_users_to_pos)):\n",
    "    len_ratio, _ = user_refinding(model, dataloader.dataset[i][0])\n",
    "    sum += len_ratio\n",
    "print('On avg we refind: ', sum/len(mapping_users_to_pos), \"% of the removed items\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
